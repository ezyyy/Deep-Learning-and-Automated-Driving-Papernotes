# [Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913)

**Problem**: Typically, loss functions of neural networks are highly non-convex and therefore possess many different local minima an optimizer can get stuck in - in fact, what one finds in general is a particular local minimum that generalizes well (see, e.g. (here)[https://stats.stackexchange.com/questions/106334/cost-function-of-neural-network-is-non-convex].
**Solution**: 

**Notes**:
* 


