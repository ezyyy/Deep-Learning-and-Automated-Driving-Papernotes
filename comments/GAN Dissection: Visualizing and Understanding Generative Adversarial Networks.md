# [GAN Dissection: Visualizing and Understanding Generative Adversarial Networks](https://arxiv.org/abs/1811.10597)

**Problem**: Learning generative models using GANs has recently brought produced impressive results in different vision tasks. However, GANs have not been well visualized or understood. How does a GAN represent our visual world internally? What causes the artifacts in GAN results? How do architectural choices affect GAN learning? Answering such questions could enable us to develop new insights and better models.


**Solution**:
**Notes**:
* TODO

