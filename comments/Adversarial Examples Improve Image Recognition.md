# [Adversarial Examples Improve Image Recognition](https://arxiv.org/pdf/1911.09665.pdf)

**Problem/Motivation**: Adversarial examples (inputs to a neural network that result in an incorrect output from the network) are commonly viewed as a threat to ConvNets. They therefore encode information that can also be leveraged to improve robustness of models. 

**Notes**: 
